# Part of RedELK
#
# In this file we configure the logstash filtes for HAproxy logs
#
# Author: Outflank B.V. / Marc Smeets
#

filter {
  if [infra][log][type] == "redirtraffic" and [redir][program] == "haproxy" {

    # Filebeat introduces the source field for the name of the log file path. But this collides with source object from the Elastic Common Schema.
    # We have no need for the filebeat's field as its also stored in log.file.path. So we drop it.
    mutate {
      remove_field => [ "source" ]
    }

    # drop haproxy log lines about the service starting and stopping
    if "haproxy-systemd-wrapper" in [message] {
      drop { }
    }
    if "Proxy " in [message] and " started." in [message] {
      drop { }
    }
    # drop haproxy log lines when there is a config error
    if " [ALERT] " in [message] {
       drop { }
    }
    if " [ SSL] " in [message] {
       drop { }
    }
    if " [ ALL] " in [message] {
       drop { }
    }
    if " [UNIX] " in [message] {
       drop { }
    }
    if " [STAT] " in [message] {
       drop { }
    }
    if " [ TCP] " in [message] {
       drop { }
    }
    if " [WARNING] " in [message] {
       drop { }
    }

    # Let's first trim the syslog info from the log line
    grok {
      match => { "message" => ["%{SYSLOGTIMESTAMP:syslogtimestamp} %{NOTSPACE:[host][name]} %{PROG:[process][name]}(?:\[%{POSINT:[process][pid]}\])?: %{GREEDYDATA:messagenosyslog}"] }
    }

    mutate {
      remove_field => [ "syslogtimestamp" ]
    }

    # Sometimes HAproxy will report an SSL handshake failure, using a different log line. We check for that as well
    if "SSL handshake failure" in [message] {
      grok {
        match => { "messagenosyslog" => [ "%{IPORHOST:[source][ip]}:%{POSINT:[source][port]} \[(?<[redir][timestamp]>%{MONTHDAY}\/%{MONTH}\/%{YEAR}:%{TIME})\] (?<[redir][frontend][name]>([^/]*))%{GREEDYDATA:[http][request][body][content]}" ] }
      }
      mutate {
        add_field => { "[redir][backend][name]" => "ssl-error" }
      }
      # Set the timestamp from the log to @timestamp, example: 16/Sep/2018:07:08:21.783
      date {
        match => [ "[redir][timestamp]", "dd/MMM/yyyy:HH:mm:ss.SSS" ]
        target => "@timestamp"
        timezone => "Etc/UTC"
      }
    }

    # now matching the real haproxy lines. We have several log line formats we need to match:
    # - Lines without X-Forwarded-For identified with "xforwardedfor:-"
    # - Lines with X-Forwarded-For set, identified with "xforwardedfor:$SOMEIP"
    # - any other weird sitution, i.e. cutoff lines when the log lne is larger than the redir's logbuffer size
    # Sometimes HAProxy reports lines with 'message repeated X times' in it. This is inserted into the line after the SYSLOGPROG, before "frontend. So we grok match (%{GREEDYDATA})? in each line
    #
    # We'll walk through them one by one
    #

    if "xforwardedfor:-" in [message] {
      # Lines without X-Forwarded-For identified with "xforwardedfor:-"
      grok {
        match => { "messagenosyslog" => [ "GMT:%{HTTPDATE:[redir][timestamp]} frontend:(?<[redir][frontend][name]>([^/]*))/(([^/]*))/%{IPORHOST:[redir][frontend][ip]}:%{POSINT:[redir][frontend][port]} backend:%{NOTSPACE:[redir][backend][name]} client:%{IPORHOST:[source][ip]}:%{POSINT:[source][port]} xforwardedfor:- headers:\{\|(?<[http][headers][all]>([^\}]*))} statuscode:%{INT:[http][response][status_code]} request:%{GREEDYDATA:[http][request][body][content]}" ] }
      }
    } else if "request:" in [message] {
      # Lines with X-Forwarded-For set. We already filtered out the 'xfordwardedfor:-', so anything left with a large enough log line should be good
      grok {
        match => { "messagenosyslog" => [ "GMT:%{HTTPDATE:[redir][timestamp]} frontend:(?<[redir][frontend][name]>([^/]*))/(([^/]*))/%{IPORHOST:[redir][frontend][ip]}:%{POSINT:[redir][frontend][port]} backend:%{NOTSPACE:[redir][backend][name]} client:%{IPORHOST:[source][cdn][ip]}:%{POSINT:[source][cdn][port]} xforwardedfor:%{IPORHOST:[source][ip]} headers:\{\|(?<[http][headers][all]>([^\}]*))} statuscode:%{INT:[http][response][status_code]} request:%{GREEDYDATA:[http][request][body][content]}" ] }
        add_tag => [ "redirtrafficxforwardedfor" ]
      }
    } else {
    # catchall situation, i.e. cutoff lines when the log lne is larger than the redir's logbuffer size
      grok {
        match => { "messagenosyslog" => [ "GMT:%{HTTPDATE:[redir][timestamp]} frontend:(?<[redir][frontend][name]>([^/]*))/(([^/]*))/%{IPORHOST:[redir][frontend][ip]}:%{POSINT:[redir][frontend][port]} backend:%{NOTSPACE:[redir][backend][name]} %{GREEDYDATA:[redir][catchall]}" ] }
        add_tag => [ "redirlongmessagecatchall" ]
      }
    }

    if [messagenosyslog] {
      mutate {
        remove_field => [ "messagenosyslog" ]
      }
    }

    # map header values onto dedicated fields and split the values of the headersall field into an array
    if [http][headers][all] {
      # map to dedicated fields
      grok {
        match => { "[http][headers][all]" => [ "(?<[http][headers][useragent]>([^|]*))\|(?<[http][headers][host]>([^|]*))\|(?<[http][headers][x_forwarded_for]>([^|]*))\|(?<[http][headers][x_forwarded_proto]>([^|]*))\|(?<[http][headers][x_host]>([^|]*))\|(?<[http][headers][forwarded]>([^|]*))\|(?<[http][headers][via]>([^|]*))" ] }
      }

      # split the values into an array
      mutate {
        split => { "[http][headers][all]" => "|" }
      }

      # Add useragent data
      if [http][headers][useragent] {
        useragent {
          source => "[http][headers][useragent]"
          target => "[source][host_info]"
        }
      }
    }

    # Set the timestamp from the log to @timestamp, example: 15/Apr/2018:19:22:31 +0000
    date {
      match => [ "[redir][timestamp]", "dd/MMM/yyyy:HH:mm:ss Z" ]
      target => "@timestamp"
      timezone => "Etc/UTC"
    }

    # When IPv6 is enabled on your HAProxy host, IPV4 addresses are reported like ::ffff:ipv4address. Here we cut off the ::ffff: part
    if "ffff" in [source][ip] {
      mutate {
        gsub => [
          "[source][ip]", "\:\:ffff\:", ""
        ]
      }
    }
    if "ffff" in [frontend][ip] {
      mutate {
        gsub => [
          "[frontend][ip]", "\:\:ffff\:", ""
        ]
      }
    }
    if "ffff" in [source][cdn][ip] {
      mutate {
        gsub => [
          "[source][cdn][ip]", "\:\:ffff\:", ""
        ]
      }
    }

    # Add data to the redirraffic.sourceip
    if [source][ip] {
      # matches the source ip with any ip in the different ip lists
      elasticsearch {
        hosts => "https://localhost:9200"
        index => "iplist_*"
        query => "ip:%{[source][ip]}"
        fields => { "type" => "iplist" }
        result_size => 1
        enable_sort => false
        user => ["logstash"]
        password => ["{{es_logstash_system_password}}"]
        ca_file => "/etc/logstash/redelkCA.crt"
      }

      # unknown IP
      if ![iplist] {
        # checking with greynoise
        # ruby {
        #   path => "/usr/share/redelk/bin/greynoise.rb"
        # }
      } else {
        mutate {
          add_tag => [ "iplist_%{iplist}" ]
        }
      }
      # duplicate field so we can replace it with reverse DNS lookup
      mutate {
        add_field => { "[source][domain]" => "%{[source][ip]}" }
      }
      # do reverse DNS lookup
      dns {
        reverse => ["[source][domain]"]
        action => "replace"
        timeout => "2.0"
      }
      # add geo ip info from City DB
      geoip {
        source => "[source][ip]"
        target => "tmpgeoip"
      }
      # add geo ip info from ASN DB
      geoip {
        source => "[source][ip]"
        target => "tmpgeoip"
        default_database_type => "ASN"
        database => "/usr/share/elasticsearch/modules/ingest-geoip/GeoLite2-ASN.mmdb"
      }
      mutate {
        copy => {
          "[tmpgeoip][as_org]" => "[source][geo][as][organization][name]"
          "[tmpgeoip][asn]" => "[source][geo][as][organization][number]"
          "[tmpgeoip][city_name]" => "[source][geo][city_name]"
          "[tmpgeoip][country_code2]" => "[source][geo][country_iso_code]"
          "[tmpgeoip][location]" => "[source][geo][location]"
          "[tmpgeoip][region_code]" => "[source][geo][region_iso_code]"
          "[tmpgeoip][region_name]" => "[source][geo][region_name]"
        }
        remove_field => [ "tmpgeoip" ]
      }
    }
    # Add data to the redirtraffic.sourceipcdn
    if [source][cdn][ip] {
      # matches the source ip with any ip in the different ip lists
      elasticsearch {
        hosts => "https://localhost:9200"
        index => "iplist_*"
        query => "ip:%{[source][cdn][ip]}"
        fields => { "type" => "iplist" }
        result_size => 1
        enable_sort => false
        user => ["logstash"]
        password => ["{{es_logstash_system_password}}"]
        ca_file => "/etc/logstash/redelkCA.crt"
      }

      # unknown IP
      if ![iplist] {
        # checking with greynoise
        # ruby {
        #   path => "/usr/share/redelk/bin/greynoise.rb"
        # }
      } else {
        mutate {
          add_tag => [ "iplist_%{iplist}" ]
        }
      }
      # duplicate field so we can replace it with reverse DNS lookup
      mutate {
        add_field => { "[source][cdn][domain]" => "%{[source][cdn][ip]}" }
      }
      # do reverse DNS lookup
      dns {
        reverse => ["[source][cdn][domain]"]
        action => "replace"
        timeout => "2.0"
      }
    }
  }
}
